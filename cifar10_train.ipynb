{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x231cc2bfb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\n",
      "\n",
      "(128, 4, 32, 32, 3)\n",
      "conv1\n",
      "\t(128, 4, 32, 32, 3) --> (128, 4, 32, 32, 64)\n",
      "pool1\n",
      "\t(128, 4, 32, 32, 64) --> (128, 4, 16, 16, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm1\n",
      "\t(128, 4, 16, 16, 64) --> (128, 4, 16, 16, 64)\n",
      "conv2\n",
      "\t(128, 4, 16, 16, 64) --> (128, 4, 16, 16, 64)\n",
      "norm2\n",
      "\t(128, 4, 16, 16, 64) --> (128, 4, 16, 16, 64)\n",
      "pool2\n",
      "\t(128, 4, 16, 16, 64) --> (128, 4, 8, 8, 64)\n",
      "conv2\n",
      "\t(128, 4, 8, 8, 64) --> (128, 4, 8, 8, 64)\n",
      "norm3\n",
      "\t(128, 4, 8, 8, 64) --> (128, 4, 8, 8, 64)\n",
      "pool3\n",
      "\t(128, 4, 8, 8, 64) --> (128, 4, 4, 4, 64)\n",
      "conv4\n",
      "\t(128, 4, 4, 4, 64) --> (128, 4, 4, 4, 64)\n",
      "norm3\n",
      "\t(128, 4, 4, 4, 64) --> (128, 4, 4, 4, 64)\n",
      "pool4\n",
      "\t(128, 4, 4, 4, 64) --> (128, 4, 2, 2, 64)\n",
      "conv5\n",
      "\t(128, 4, 2, 2, 64) --> (128, 4, 2, 2, 64)\n",
      "norm5\n",
      "\t(128, 4, 2, 2, 64) --> (128, 4, 4, 4, 64)\n",
      "pool5\n",
      "\t(128, 4, 4, 4, 64) --> (128, 4, 2, 2, 64)\n",
      "INFO:tensorflow:Summary name conv1/weight_loss (raw) is illegal; using conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv2/weight_loss (raw) is illegal; using conv2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv3/weight_loss (raw) is illegal; using conv3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv4/weight_loss (raw) is illegal; using conv4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv5/weight_loss (raw) is illegal; using conv5/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/cifar10_train\\model.ckpt.\n",
      "128\n",
      "2018-06-02 22:27:15.808143: step 0, loss = 3.46 (120.8 examples/sec; 1.060 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:17.957552: step 10, loss = 3.23 (595.2 examples/sec; 0.215 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:20.002319: step 20, loss = 3.09 (626.0 examples/sec; 0.204 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:22.030825: step 30, loss = 3.03 (631.0 examples/sec; 0.203 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:24.092928: step 40, loss = 2.99 (620.7 examples/sec; 0.206 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:26.159680: step 50, loss = 2.98 (619.3 examples/sec; 0.207 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:28.232287: step 60, loss = 3.04 (617.9 examples/sec; 0.207 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:30.333982: step 70, loss = 2.90 (609.0 examples/sec; 0.210 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:32.401739: step 80, loss = 2.71 (618.7 examples/sec; 0.207 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:34.484661: step 90, loss = 2.58 (614.5 examples/sec; 0.208 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 4.23129\n",
      "128\n",
      "2018-06-02 22:27:37.875656: step 100, loss = 2.79 (378.5 examples/sec; 0.338 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:39.951951: step 110, loss = 2.50 (613.8 examples/sec; 0.209 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:42.005330: step 120, loss = 2.57 (623.4 examples/sec; 0.205 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:44.063803: step 130, loss = 2.46 (621.8 examples/sec; 0.206 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:46.171634: step 140, loss = 2.75 (607.5 examples/sec; 0.211 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:48.301695: step 150, loss = 2.48 (600.6 examples/sec; 0.213 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:50.443890: step 160, loss = 2.40 (597.5 examples/sec; 0.214 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:52.603041: step 170, loss = 2.56 (592.8 examples/sec; 0.216 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:54.739313: step 180, loss = 2.43 (599.2 examples/sec; 0.214 sec/batch)\n",
      "128\n",
      "2018-06-02 22:27:56.928675: step 190, loss = 2.39 (584.6 examples/sec; 0.219 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 4.47347\n",
      "128\n",
      "2018-06-02 22:28:00.204759: step 200, loss = 2.53 (390.7 examples/sec; 0.328 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:02.311251: step 210, loss = 2.42 (607.6 examples/sec; 0.211 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:04.464075: step 220, loss = 2.26 (594.6 examples/sec; 0.215 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:06.669898: step 230, loss = 2.32 (580.5 examples/sec; 0.220 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:08.857058: step 240, loss = 2.35 (585.2 examples/sec; 0.219 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:11.114425: step 250, loss = 2.28 (567.0 examples/sec; 0.226 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:13.368016: step 260, loss = 2.25 (567.7 examples/sec; 0.225 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:15.631142: step 270, loss = 2.23 (565.8 examples/sec; 0.226 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:18.034117: step 280, loss = 2.40 (532.9 examples/sec; 0.240 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:20.444937: step 290, loss = 2.20 (530.5 examples/sec; 0.241 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 4.15301\n",
      "128\n",
      "2018-06-02 22:28:24.293631: step 300, loss = 2.30 (332.6 examples/sec; 0.385 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:26.425865: step 310, loss = 2.13 (600.3 examples/sec; 0.213 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:28.544199: step 320, loss = 2.05 (604.2 examples/sec; 0.212 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:30.662762: step 330, loss = 2.05 (604.2 examples/sec; 0.212 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:32.798879: step 340, loss = 2.08 (599.2 examples/sec; 0.214 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:34.999105: step 350, loss = 2.21 (581.8 examples/sec; 0.220 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:37.108189: step 360, loss = 2.03 (606.9 examples/sec; 0.211 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:39.290381: step 370, loss = 1.89 (586.6 examples/sec; 0.218 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:41.451346: step 380, loss = 2.06 (592.3 examples/sec; 0.216 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:43.655222: step 390, loss = 2.13 (580.8 examples/sec; 0.220 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 4.29416\n",
      "128\n",
      "2018-06-02 22:28:47.619996: step 400, loss = 1.97 (322.8 examples/sec; 0.396 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:49.827953: step 410, loss = 2.13 (579.7 examples/sec; 0.221 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:52.053477: step 420, loss = 2.08 (575.1 examples/sec; 0.223 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:54.241169: step 430, loss = 1.97 (585.1 examples/sec; 0.219 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:56.365371: step 440, loss = 1.93 (602.6 examples/sec; 0.212 sec/batch)\n",
      "128\n",
      "2018-06-02 22:28:58.530885: step 450, loss = 1.87 (591.1 examples/sec; 0.217 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:00.697839: step 460, loss = 1.98 (590.7 examples/sec; 0.217 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:02.834422: step 470, loss = 1.84 (599.1 examples/sec; 0.214 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:04.976900: step 480, loss = 1.75 (597.4 examples/sec; 0.214 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:07.125591: step 490, loss = 2.17 (595.7 examples/sec; 0.215 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 4.35739\n",
      "128\n",
      "2018-06-02 22:29:10.549818: step 500, loss = 1.83 (375.0 examples/sec; 0.341 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:13.479008: step 510, loss = 1.84 (437.7 examples/sec; 0.292 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:16.535787: step 520, loss = 1.85 (416.6 examples/sec; 0.307 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:19.609005: step 530, loss = 1.81 (416.6 examples/sec; 0.307 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:22.667748: step 540, loss = 2.04 (418.5 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:25.683165: step 550, loss = 1.83 (424.5 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:28.721042: step 560, loss = 1.87 (421.2 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:31.737976: step 570, loss = 1.95 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:34.760891: step 580, loss = 1.72 (423.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:37.752313: step 590, loss = 1.81 (427.9 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.15742\n",
      "128\n",
      "2018-06-02 22:29:42.197050: step 600, loss = 1.89 (288.0 examples/sec; 0.444 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:45.186025: step 610, loss = 1.74 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:48.195980: step 620, loss = 1.60 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:51.211912: step 630, loss = 1.84 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:54.220900: step 640, loss = 1.81 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:29:57.203889: step 650, loss = 1.67 (429.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:00.182948: step 660, loss = 1.68 (429.8 examples/sec; 0.298 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 22:30:03.159963: step 670, loss = 1.75 (430.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:06.138998: step 680, loss = 1.49 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:09.120025: step 690, loss = 1.82 (429.2 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20175\n",
      "128\n",
      "2018-06-02 22:30:13.444924: step 700, loss = 1.72 (296.7 examples/sec; 0.431 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:16.439915: step 710, loss = 1.76 (425.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:19.427968: step 720, loss = 1.61 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:22.443904: step 730, loss = 1.77 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:25.441856: step 740, loss = 1.56 (427.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:28.441834: step 750, loss = 1.58 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:31.463579: step 760, loss = 1.43 (423.6 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:34.463497: step 770, loss = 1.51 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:37.495059: step 780, loss = 1.69 (422.4 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:40.484793: step 790, loss = 1.51 (428.0 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.06646\n",
      "128\n",
      "2018-06-02 22:30:46.063617: step 800, loss = 1.50 (229.4 examples/sec; 0.558 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:49.051273: step 810, loss = 1.34 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:52.037852: step 820, loss = 1.59 (428.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:55.060948: step 830, loss = 1.42 (423.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:30:58.061369: step 840, loss = 1.59 (426.6 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:01.042941: step 850, loss = 1.51 (429.3 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:04.044887: step 860, loss = 1.63 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:07.035090: step 870, loss = 1.43 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:10.033271: step 880, loss = 1.45 (429.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:13.006619: step 890, loss = 1.53 (428.2 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20328\n",
      "128\n",
      "2018-06-02 22:31:17.284513: step 900, loss = 1.72 (299.4 examples/sec; 0.427 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:20.294110: step 910, loss = 1.67 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:23.349042: step 920, loss = 1.44 (418.9 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:26.346840: step 930, loss = 1.23 (427.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:29.341587: step 940, loss = 1.31 (427.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:32.332013: step 950, loss = 1.44 (428.0 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:35.304723: step 960, loss = 1.50 (430.6 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:38.326900: step 970, loss = 1.56 (423.5 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:41.307943: step 980, loss = 1.47 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:44.300473: step 990, loss = 1.52 (427.9 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19014\n",
      "128\n",
      "2018-06-02 22:31:48.618741: step 1000, loss = 1.42 (297.0 examples/sec; 0.431 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:51.601892: step 1010, loss = 1.45 (427.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:54.610587: step 1020, loss = 1.49 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:31:57.603662: step 1030, loss = 1.38 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:00.583944: step 1040, loss = 1.40 (429.5 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:03.558555: step 1050, loss = 1.25 (430.3 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:06.548367: step 1060, loss = 1.40 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:09.525309: step 1070, loss = 1.38 (430.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:12.525032: step 1080, loss = 1.25 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:15.493901: step 1090, loss = 1.33 (431.0 examples/sec; 0.297 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.23566\n",
      "128\n",
      "2018-06-02 22:32:19.513610: step 1100, loss = 1.15 (318.4 examples/sec; 0.402 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:22.526604: step 1110, loss = 1.16 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:25.502662: step 1120, loss = 1.20 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:28.491012: step 1130, loss = 1.16 (428.3 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:31.463129: step 1140, loss = 1.39 (430.7 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:34.473004: step 1150, loss = 1.24 (425.3 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:37.522295: step 1160, loss = 1.36 (420.2 examples/sec; 0.305 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:40.578107: step 1170, loss = 1.31 (418.6 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:43.591050: step 1180, loss = 1.29 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:46.635933: step 1190, loss = 1.36 (420.5 examples/sec; 0.304 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19554\n",
      "128\n",
      "2018-06-02 22:32:50.807791: step 1200, loss = 1.19 (306.7 examples/sec; 0.417 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:53.827678: step 1210, loss = 1.38 (423.9 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:56.846605: step 1220, loss = 1.33 (424.0 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:32:59.858552: step 1230, loss = 1.21 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:02.894438: step 1240, loss = 1.24 (421.8 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:05.919253: step 1250, loss = 1.18 (423.0 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:08.921535: step 1260, loss = 1.24 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:11.933322: step 1270, loss = 1.24 (424.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:14.956108: step 1280, loss = 1.27 (423.5 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:17.968059: step 1290, loss = 1.15 (425.0 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19761\n",
      "128\n",
      "2018-06-02 22:33:22.095959: step 1300, loss = 1.19 (310.1 examples/sec; 0.413 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:25.106250: step 1310, loss = 1.24 (425.2 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:28.130215: step 1320, loss = 1.27 (425.5 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:31.148547: step 1330, loss = 1.25 (421.9 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:34.168428: step 1340, loss = 1.17 (424.0 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:37.186784: step 1350, loss = 1.37 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:40.182728: step 1360, loss = 1.22 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:43.182571: step 1370, loss = 1.16 (426.6 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:46.197509: step 1380, loss = 1.29 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:49.192500: step 1390, loss = 1.26 (427.2 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.16732\n",
      "128\n",
      "2018-06-02 22:33:53.655606: step 1400, loss = 1.18 (286.8 examples/sec; 0.446 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:56.626784: step 1410, loss = 1.21 (430.8 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:33:59.627753: step 1420, loss = 1.10 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:02.675567: step 1430, loss = 1.07 (419.8 examples/sec; 0.305 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:05.702866: step 1440, loss = 1.18 (422.8 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:08.716609: step 1450, loss = 1.19 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:11.747503: step 1460, loss = 1.31 (422.5 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:14.753465: step 1470, loss = 1.08 (425.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:17.738482: step 1480, loss = 1.00 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:20.745475: step 1490, loss = 1.06 (425.7 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.17611\n",
      "128\n",
      "2018-06-02 22:34:25.149666: step 1500, loss = 1.06 (291.0 examples/sec; 0.440 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:28.212475: step 1510, loss = 1.12 (417.1 examples/sec; 0.307 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 22:34:31.229408: step 1520, loss = 1.05 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:34.254321: step 1530, loss = 1.08 (423.0 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:37.241553: step 1540, loss = 0.98 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:40.222301: step 1550, loss = 1.19 (429.6 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:43.204446: step 1560, loss = 1.23 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:46.197484: step 1570, loss = 1.10 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:49.187495: step 1580, loss = 1.03 (428.0 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:52.189763: step 1590, loss = 1.05 (426.5 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20767\n",
      "128\n",
      "2018-06-02 22:34:56.345925: step 1600, loss = 1.06 (308.3 examples/sec; 0.415 sec/batch)\n",
      "128\n",
      "2018-06-02 22:34:59.338869: step 1610, loss = 1.00 (427.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:02.339330: step 1620, loss = 1.03 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:05.335318: step 1630, loss = 1.05 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:08.321334: step 1640, loss = 0.98 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:11.318320: step 1650, loss = 1.03 (427.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:14.338276: step 1660, loss = 1.11 (423.8 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:17.339225: step 1670, loss = 1.09 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:20.344189: step 1680, loss = 0.94 (425.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:23.373099: step 1690, loss = 0.94 (422.6 examples/sec; 0.303 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20155\n",
      "128\n",
      "2018-06-02 22:35:27.562884: step 1700, loss = 1.03 (306.0 examples/sec; 0.418 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:30.563857: step 1710, loss = 1.01 (425.5 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:33.568822: step 1720, loss = 1.06 (426.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:36.569799: step 1730, loss = 0.98 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:39.556848: step 1740, loss = 0.99 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:42.559789: step 1750, loss = 1.30 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:45.561794: step 1760, loss = 1.06 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:48.576691: step 1770, loss = 1.02 (424.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:51.579835: step 1780, loss = 1.09 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:35:54.582978: step 1790, loss = 1.02 (426.2 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20711\n",
      "128\n",
      "2018-06-02 22:35:58.738011: step 1800, loss = 0.94 (308.7 examples/sec; 0.415 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:01.745901: step 1810, loss = 0.93 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:04.747995: step 1820, loss = 0.84 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:07.759810: step 1830, loss = 0.96 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:10.765007: step 1840, loss = 0.95 (425.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:13.760715: step 1850, loss = 0.95 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:16.731818: step 1860, loss = 0.98 (430.8 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:19.745264: step 1870, loss = 1.01 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:22.751565: step 1880, loss = 0.75 (425.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:25.769387: step 1890, loss = 0.88 (424.1 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20473\n",
      "128\n",
      "2018-06-02 22:36:29.942559: step 1900, loss = 0.90 (307.4 examples/sec; 0.416 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:32.938922: step 1910, loss = 0.95 (425.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:35.918053: step 1920, loss = 1.31 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:38.960561: step 1930, loss = 0.86 (420.7 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:41.957120: step 1940, loss = 1.06 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:44.947172: step 1950, loss = 1.05 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:47.926160: step 1960, loss = 0.83 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:50.931462: step 1970, loss = 0.90 (425.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:53.950026: step 1980, loss = 0.77 (424.0 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:36:56.955787: step 1990, loss = 0.86 (425.8 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.18788\n",
      "128\n",
      "2018-06-02 22:37:01.309373: step 2000, loss = 1.02 (294.6 examples/sec; 0.435 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:04.320731: step 2010, loss = 0.87 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:07.371483: step 2020, loss = 1.00 (419.6 examples/sec; 0.305 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:10.442090: step 2030, loss = 0.90 (416.9 examples/sec; 0.307 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:13.445631: step 2040, loss = 1.00 (426.2 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2044 into /tmp/cifar10_train\\model.ckpt.\n",
      "128\n",
      "2018-06-02 22:37:18.180255: step 2050, loss = 1.07 (270.3 examples/sec; 0.474 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:21.179721: step 2060, loss = 0.98 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:24.144456: step 2070, loss = 1.07 (431.7 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:27.153716: step 2080, loss = 0.88 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:30.174912: step 2090, loss = 1.00 (423.7 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.04332\n",
      "128\n",
      "2018-06-02 22:37:34.161499: step 2100, loss = 1.04 (321.1 examples/sec; 0.399 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:37.169811: step 2110, loss = 0.99 (425.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:40.180223: step 2120, loss = 0.98 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:43.182364: step 2130, loss = 0.96 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:46.172071: step 2140, loss = 1.02 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:49.142656: step 2150, loss = 0.78 (430.9 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:52.124199: step 2160, loss = 0.84 (429.3 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:55.124382: step 2170, loss = 1.02 (426.6 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:37:58.108169: step 2180, loss = 0.80 (429.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:01.080521: step 2190, loss = 0.95 (430.8 examples/sec; 0.297 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.23793\n",
      "128\n",
      "2018-06-02 22:38:05.043479: step 2200, loss = 0.89 (322.9 examples/sec; 0.396 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:08.039070: step 2210, loss = 0.94 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:11.058160: step 2220, loss = 0.68 (424.0 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:14.039495: step 2230, loss = 0.91 (429.3 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:17.029076: step 2240, loss = 0.85 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:20.021539: step 2250, loss = 0.98 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:23.013726: step 2260, loss = 0.78 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:26.001282: step 2270, loss = 0.92 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:28.973404: step 2280, loss = 0.93 (430.8 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:31.957317: step 2290, loss = 0.77 (428.8 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22443\n",
      "128\n",
      "2018-06-02 22:38:36.076305: step 2300, loss = 0.90 (311.4 examples/sec; 0.411 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:39.080296: step 2310, loss = 0.83 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:42.065024: step 2320, loss = 0.82 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:45.041233: step 2330, loss = 0.89 (430.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:48.029738: step 2340, loss = 0.84 (428.3 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:51.008349: step 2350, loss = 0.72 (429.7 examples/sec; 0.298 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 22:38:54.002234: step 2360, loss = 1.21 (427.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:56.992108: step 2370, loss = 0.83 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:38:59.977477: step 2380, loss = 0.92 (428.9 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:02.953628: step 2390, loss = 0.77 (430.1 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21212\n",
      "128\n",
      "2018-06-02 22:39:07.204426: step 2400, loss = 0.78 (302.0 examples/sec; 0.424 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:10.185588: step 2410, loss = 0.78 (427.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:13.158135: step 2420, loss = 0.82 (430.6 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:16.146629: step 2430, loss = 0.80 (428.3 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:19.121903: step 2440, loss = 0.67 (430.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:22.140534: step 2450, loss = 0.68 (424.2 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:25.157271: step 2460, loss = 0.89 (424.2 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:28.121929: step 2470, loss = 0.89 (431.8 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:31.138185: step 2480, loss = 0.75 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:34.096495: step 2490, loss = 0.80 (432.7 examples/sec; 0.296 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22165\n",
      "128\n",
      "2018-06-02 22:39:38.237426: step 2500, loss = 0.97 (309.1 examples/sec; 0.414 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:41.229425: step 2510, loss = 0.75 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:44.324429: step 2520, loss = 0.87 (413.7 examples/sec; 0.309 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:47.341741: step 2530, loss = 0.76 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:50.340722: step 2540, loss = 0.75 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:53.344452: step 2550, loss = 0.80 (426.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:56.337274: step 2560, loss = 0.80 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:39:59.319636: step 2570, loss = 0.90 (429.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:02.315162: step 2580, loss = 0.79 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:05.294932: step 2590, loss = 0.79 (429.6 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20134\n",
      "128\n",
      "2018-06-02 22:40:09.473388: step 2600, loss = 0.68 (306.8 examples/sec; 0.417 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:12.448967: step 2610, loss = 0.68 (429.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:15.428392: step 2620, loss = 0.88 (429.6 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:18.410648: step 2630, loss = 0.81 (429.3 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:21.391068: step 2640, loss = 0.75 (429.3 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:24.372588: step 2650, loss = 0.60 (429.3 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:27.383040: step 2660, loss = 0.68 (425.2 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:30.401778: step 2670, loss = 0.76 (424.2 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:33.404122: step 2680, loss = 0.84 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:36.400925: step 2690, loss = 0.75 (427.1 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22096\n",
      "128\n",
      "2018-06-02 22:40:40.532351: step 2700, loss = 0.71 (309.8 examples/sec; 0.413 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:43.538119: step 2710, loss = 0.88 (425.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:46.538600: step 2720, loss = 0.81 (426.6 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:49.531778: step 2730, loss = 0.69 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:52.533047: step 2740, loss = 0.81 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:55.551534: step 2750, loss = 0.83 (423.9 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:40:58.617972: step 2760, loss = 0.71 (417.7 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:01.653257: step 2770, loss = 0.58 (421.6 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:04.689069: step 2780, loss = 0.83 (421.6 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:07.714841: step 2790, loss = 0.79 (422.9 examples/sec; 0.303 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.16476\n",
      "128\n",
      "2018-06-02 22:41:12.118992: step 2800, loss = 0.76 (291.1 examples/sec; 0.440 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:15.101764: step 2810, loss = 0.79 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:18.082446: step 2820, loss = 0.66 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:21.074164: step 2830, loss = 0.81 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:24.066358: step 2840, loss = 0.77 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:27.061800: step 2850, loss = 0.76 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:30.026374: step 2860, loss = 0.80 (431.8 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:33.017615: step 2870, loss = 0.89 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:35.998952: step 2880, loss = 0.73 (429.5 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:38.980253: step 2890, loss = 0.68 (429.3 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.23233\n",
      "128\n",
      "2018-06-02 22:41:43.050488: step 2900, loss = 0.83 (314.4 examples/sec; 0.407 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:46.014769: step 2910, loss = 0.67 (431.8 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:49.013808: step 2920, loss = 0.70 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:52.009206: step 2930, loss = 0.71 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:55.003302: step 2940, loss = 0.83 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:41:58.028539: step 2950, loss = 0.66 (423.1 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:01.005442: step 2960, loss = 0.80 (430.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:04.010761: step 2970, loss = 0.71 (425.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:06.999622: step 2980, loss = 0.78 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:09.989001: step 2990, loss = 0.69 (428.0 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19058\n",
      "128\n",
      "2018-06-02 22:42:14.386990: step 3000, loss = 0.70 (291.0 examples/sec; 0.440 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:17.380325: step 3010, loss = 0.67 (427.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:20.382205: step 3020, loss = 0.83 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:23.361195: step 3030, loss = 0.80 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:26.320289: step 3040, loss = 0.59 (432.6 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:29.293418: step 3050, loss = 0.72 (430.5 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:32.282366: step 3060, loss = 0.80 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:35.264512: step 3070, loss = 0.63 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:38.239004: step 3080, loss = 0.72 (430.3 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:41.216856: step 3090, loss = 0.67 (429.9 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.2203\n",
      "128\n",
      "2018-06-02 22:42:45.450408: step 3100, loss = 0.53 (302.3 examples/sec; 0.423 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:48.469532: step 3110, loss = 0.74 (424.0 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:51.458342: step 3120, loss = 0.61 (428.3 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:54.449830: step 3130, loss = 0.58 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:42:57.457375: step 3140, loss = 0.63 (425.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:00.433747: step 3150, loss = 0.65 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:03.425119: step 3160, loss = 0.61 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:06.398381: step 3170, loss = 0.61 (430.5 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:09.384148: step 3180, loss = 0.65 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:12.372331: step 3190, loss = 0.85 (428.4 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19542\n",
      "128\n",
      "2018-06-02 22:43:16.738551: step 3200, loss = 0.87 (293.2 examples/sec; 0.437 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 22:43:19.734210: step 3210, loss = 0.69 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:22.726405: step 3220, loss = 0.56 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:25.727794: step 3230, loss = 0.74 (426.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:28.745603: step 3240, loss = 0.70 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:31.753871: step 3250, loss = 0.73 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:34.761188: step 3260, loss = 0.69 (425.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:37.773987: step 3270, loss = 0.59 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:40.771454: step 3280, loss = 0.55 (426.9 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:43.766821: step 3290, loss = 0.68 (427.3 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.90267\n",
      "128\n",
      "2018-06-02 22:43:51.233536: step 3300, loss = 0.63 (171.7 examples/sec; 0.745 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:54.239008: step 3310, loss = 0.78 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:43:57.249567: step 3320, loss = 0.71 (425.2 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:00.292050: step 3330, loss = 0.70 (420.7 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:03.306827: step 3340, loss = 0.72 (424.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:06.321389: step 3350, loss = 0.59 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:09.382431: step 3360, loss = 0.61 (418.0 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:12.376460: step 3370, loss = 0.66 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:15.362411: step 3380, loss = 0.64 (428.8 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:18.357752: step 3390, loss = 0.59 (427.3 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.16469\n",
      "128\n",
      "2018-06-02 22:44:22.794152: step 3400, loss = 0.61 (288.5 examples/sec; 0.444 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:25.756292: step 3410, loss = 0.66 (432.1 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:28.735202: step 3420, loss = 0.53 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:31.722232: step 3430, loss = 0.68 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:34.704947: step 3440, loss = 0.76 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:37.718733: step 3450, loss = 0.83 (424.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:40.698588: step 3460, loss = 0.65 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:43.680284: step 3470, loss = 0.63 (429.3 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:46.672844: step 3480, loss = 0.65 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:49.665734: step 3490, loss = 0.72 (427.7 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22417\n",
      "128\n",
      "2018-06-02 22:44:53.801997: step 3500, loss = 0.54 (309.5 examples/sec; 0.414 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:56.784289: step 3510, loss = 0.63 (429.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:44:59.764709: step 3520, loss = 0.66 (429.5 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:02.742033: step 3530, loss = 0.75 (429.9 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:05.757939: step 3540, loss = 0.61 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:08.761917: step 3550, loss = 0.54 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:11.775871: step 3560, loss = 0.61 (424.5 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:14.796800: step 3570, loss = 0.73 (423.7 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:17.796474: step 3580, loss = 0.70 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:20.833969: step 3590, loss = 0.53 (421.4 examples/sec; 0.304 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20381\n",
      "128\n",
      "2018-06-02 22:45:25.014772: step 3600, loss = 0.50 (306.2 examples/sec; 0.418 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:28.014394: step 3610, loss = 0.49 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:31.015301: step 3620, loss = 0.66 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:34.003042: step 3630, loss = 0.70 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:36.984527: step 3640, loss = 0.46 (429.5 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:40.024441: step 3650, loss = 0.66 (421.1 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:43.040511: step 3660, loss = 0.60 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:46.060533: step 3670, loss = 0.70 (423.8 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:49.072652: step 3680, loss = 0.55 (425.1 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:52.115442: step 3690, loss = 0.77 (420.5 examples/sec; 0.304 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19782\n",
      "128\n",
      "2018-06-02 22:45:56.296817: step 3700, loss = 0.85 (306.1 examples/sec; 0.418 sec/batch)\n",
      "128\n",
      "2018-06-02 22:45:59.280020: step 3710, loss = 0.56 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:02.286888: step 3720, loss = 0.58 (425.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:05.303692: step 3730, loss = 0.49 (424.2 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:08.294863: step 3740, loss = 0.54 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:11.272344: step 3750, loss = 0.55 (429.9 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:14.268907: step 3760, loss = 0.56 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:17.259566: step 3770, loss = 0.46 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:20.274537: step 3780, loss = 0.64 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:23.284064: step 3790, loss = 0.48 (425.6 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.16334\n",
      "128\n",
      "2018-06-02 22:46:27.913236: step 3800, loss = 0.72 (276.9 examples/sec; 0.462 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:30.892409: step 3810, loss = 0.55 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:33.894316: step 3820, loss = 0.66 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:36.899944: step 3830, loss = 0.44 (426.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:39.863503: step 3840, loss = 0.57 (431.8 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:42.849760: step 3850, loss = 0.60 (428.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:45.836618: step 3860, loss = 0.52 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:48.877838: step 3870, loss = 0.58 (420.9 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:52.004726: step 3880, loss = 0.54 (409.5 examples/sec; 0.313 sec/batch)\n",
      "128\n",
      "2018-06-02 22:46:55.032776: step 3890, loss = 0.61 (422.7 examples/sec; 0.303 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.13156\n",
      "128\n",
      "2018-06-02 22:46:59.861175: step 3900, loss = 0.71 (265.4 examples/sec; 0.482 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:02.896394: step 3910, loss = 0.72 (421.0 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:05.960874: step 3920, loss = 0.66 (417.6 examples/sec; 0.307 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:08.967834: step 3930, loss = 0.70 (425.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:11.981774: step 3940, loss = 0.47 (424.6 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3949 into /tmp/cifar10_train\\model.ckpt.\n",
      "128\n",
      "2018-06-02 22:47:16.990684: step 3950, loss = 0.47 (255.5 examples/sec; 0.501 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:19.983440: step 3960, loss = 0.69 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:22.949050: step 3970, loss = 0.63 (431.6 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:25.926881: step 3980, loss = 0.51 (429.8 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:28.932728: step 3990, loss = 0.53 (425.8 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.99539\n",
      "128\n",
      "2018-06-02 22:47:33.223820: step 4000, loss = 0.62 (298.8 examples/sec; 0.428 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:36.244568: step 4010, loss = 0.59 (422.8 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:39.241928: step 4020, loss = 0.71 (427.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:42.238559: step 4030, loss = 0.55 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:45.233259: step 4040, loss = 0.60 (427.3 examples/sec; 0.300 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 22:47:48.258480: step 4050, loss = 0.54 (423.2 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:51.239772: step 4060, loss = 0.66 (429.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:54.229691: step 4070, loss = 0.65 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:47:57.227620: step 4080, loss = 0.43 (427.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:00.200785: step 4090, loss = 0.67 (430.5 examples/sec; 0.297 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21394\n",
      "128\n",
      "2018-06-02 22:48:04.336265: step 4100, loss = 0.68 (309.5 examples/sec; 0.414 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:07.330833: step 4110, loss = 0.46 (427.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:10.352144: step 4120, loss = 0.65 (423.7 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:13.493749: step 4130, loss = 0.69 (408.0 examples/sec; 0.314 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:16.660723: step 4140, loss = 0.62 (403.8 examples/sec; 0.317 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:29.651354: step 4150, loss = 0.68 (98.5 examples/sec; 1.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:32.631333: step 4160, loss = 0.48 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:35.606380: step 4170, loss = 0.60 (430.4 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:38.579431: step 4180, loss = 0.36 (430.5 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:41.598357: step 4190, loss = 0.65 (423.9 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.3887\n",
      "128\n",
      "2018-06-02 22:48:46.223987: step 4200, loss = 0.47 (277.3 examples/sec; 0.462 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:49.200225: step 4210, loss = 0.71 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:52.202713: step 4220, loss = 0.64 (426.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:55.183727: step 4230, loss = 0.47 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:48:58.186695: step 4240, loss = 0.44 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:01.173297: step 4250, loss = 0.57 (428.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:04.163764: step 4260, loss = 0.41 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:07.169520: step 4270, loss = 0.59 (425.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:10.152962: step 4280, loss = 0.50 (429.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:13.151555: step 4290, loss = 0.43 (426.9 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19967\n",
      "128\n",
      "2018-06-02 22:49:17.448994: step 4300, loss = 0.59 (298.8 examples/sec; 0.428 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:20.419282: step 4310, loss = 0.65 (429.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:23.409053: step 4320, loss = 0.56 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:26.415056: step 4330, loss = 0.48 (425.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:29.391785: step 4340, loss = 0.49 (430.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:32.370830: step 4350, loss = 0.42 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:35.350526: step 4360, loss = 0.42 (429.6 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:38.324306: step 4370, loss = 0.48 (430.4 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:41.290413: step 4380, loss = 0.55 (431.5 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:44.260242: step 4390, loss = 0.43 (431.0 examples/sec; 0.297 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.23615\n",
      "128\n",
      "2018-06-02 22:49:48.339422: step 4400, loss = 0.46 (313.8 examples/sec; 0.408 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:51.326216: step 4410, loss = 0.51 (428.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:54.305595: step 4420, loss = 0.43 (429.6 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:49:57.263110: step 4430, loss = 0.67 (432.8 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:00.244184: step 4440, loss = 0.34 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:03.231910: step 4450, loss = 0.51 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:06.249813: step 4460, loss = 0.51 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:09.224857: step 4470, loss = 0.60 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:12.217855: step 4480, loss = 0.51 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:15.211876: step 4490, loss = 0.59 (427.5 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.23177\n",
      "128\n",
      "2018-06-02 22:50:19.334835: step 4500, loss = 0.62 (311.2 examples/sec; 0.411 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:22.387692: step 4510, loss = 0.52 (417.8 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:25.366695: step 4520, loss = 0.42 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:28.351713: step 4530, loss = 0.50 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:31.341718: step 4540, loss = 0.35 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:34.340699: step 4550, loss = 0.54 (427.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:37.372591: step 4560, loss = 0.52 (422.2 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:40.372568: step 4570, loss = 0.38 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:43.388505: step 4580, loss = 0.40 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:46.367564: step 4590, loss = 0.50 (429.7 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21311\n",
      "128\n",
      "2018-06-02 22:50:50.418481: step 4600, loss = 0.42 (316.0 examples/sec; 0.405 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:53.445162: step 4610, loss = 0.58 (423.0 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:56.460617: step 4620, loss = 0.47 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:50:59.459182: step 4630, loss = 0.61 (426.9 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:02.438230: step 4640, loss = 0.51 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:05.434204: step 4650, loss = 0.46 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:08.436180: step 4660, loss = 0.42 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:11.440151: step 4670, loss = 0.48 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:14.427639: step 4680, loss = 0.43 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:17.419339: step 4690, loss = 0.56 (427.9 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19014\n",
      "128\n",
      "2018-06-02 22:51:21.768873: step 4700, loss = 0.52 (294.4 examples/sec; 0.435 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:24.732311: step 4710, loss = 0.57 (431.8 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:27.691950: step 4720, loss = 0.47 (432.5 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:30.686419: step 4730, loss = 0.43 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:33.685483: step 4740, loss = 0.59 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:36.692208: step 4750, loss = 0.44 (425.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:39.684049: step 4760, loss = 0.41 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:42.681280: step 4770, loss = 0.58 (427.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:45.644415: step 4780, loss = 0.57 (432.0 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:48.637798: step 4790, loss = 0.48 (427.8 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22466\n",
      "128\n",
      "2018-06-02 22:51:52.777832: step 4800, loss = 0.60 (310.3 examples/sec; 0.413 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:55.751704: step 4810, loss = 0.49 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:51:58.753409: step 4820, loss = 0.50 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:01.745419: step 4830, loss = 0.59 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:04.717463: step 4840, loss = 0.41 (430.7 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:07.715442: step 4850, loss = 0.53 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:10.715421: step 4860, loss = 0.50 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:13.701436: step 4870, loss = 0.56 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:16.697425: step 4880, loss = 0.59 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:19.680450: step 4890, loss = 0.55 (429.1 examples/sec; 0.298 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.21944\n",
      "128\n",
      "2018-06-02 22:52:23.845312: step 4900, loss = 0.39 (307.8 examples/sec; 0.416 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:26.816368: step 4910, loss = 0.65 (429.8 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:29.788421: step 4920, loss = 0.48 (430.7 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:32.771482: step 4930, loss = 0.50 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:35.765457: step 4940, loss = 0.46 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:38.741480: step 4950, loss = 0.45 (430.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:41.739618: step 4960, loss = 0.59 (427.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:44.756549: step 4970, loss = 0.46 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:47.774787: step 4980, loss = 0.42 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:50.798886: step 4990, loss = 0.43 (423.3 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.2115\n",
      "128\n",
      "2018-06-02 22:52:54.981355: step 5000, loss = 0.35 (306.0 examples/sec; 0.418 sec/batch)\n",
      "128\n",
      "2018-06-02 22:52:58.018426: step 5010, loss = 0.56 (421.5 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:01.007030: step 5020, loss = 0.62 (428.3 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:03.987638: step 5030, loss = 0.58 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:06.983783: step 5040, loss = 0.49 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:09.992492: step 5050, loss = 0.62 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:13.001052: step 5060, loss = 0.58 (425.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:16.013958: step 5070, loss = 0.57 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:19.002964: step 5080, loss = 0.40 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:21.992940: step 5090, loss = 0.50 (428.2 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20008\n",
      "128\n",
      "2018-06-02 22:53:26.225615: step 5100, loss = 0.85 (302.8 examples/sec; 0.423 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:29.190688: step 5110, loss = 0.34 (431.0 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:32.202540: step 5120, loss = 0.36 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:35.215766: step 5130, loss = 0.54 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:38.234449: step 5140, loss = 0.50 (424.2 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:41.222370: step 5150, loss = 0.44 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:44.201648: step 5160, loss = 0.47 (429.6 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:47.202795: step 5170, loss = 0.52 (426.6 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:50.198883: step 5180, loss = 0.29 (427.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:53:53.205588: step 5190, loss = 0.58 (425.7 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22048\n",
      "128\n",
      "2018-06-02 22:53:57.259649: step 5200, loss = 0.51 (315.7 examples/sec; 0.405 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:00.263617: step 5210, loss = 0.40 (426.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:03.255654: step 5220, loss = 0.31 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:06.242635: step 5230, loss = 0.46 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:09.227650: step 5240, loss = 0.55 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:12.238598: step 5250, loss = 0.48 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:15.223769: step 5260, loss = 0.56 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:18.222185: step 5270, loss = 0.49 (427.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:21.225602: step 5280, loss = 0.49 (426.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:24.217601: step 5290, loss = 0.55 (427.8 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22457\n",
      "128\n",
      "2018-06-02 22:54:28.289745: step 5300, loss = 0.41 (314.3 examples/sec; 0.407 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:31.313626: step 5310, loss = 0.56 (423.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:34.298672: step 5320, loss = 0.41 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:37.312623: step 5330, loss = 0.44 (424.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:40.287631: step 5340, loss = 0.50 (430.3 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:43.265668: step 5350, loss = 0.56 (429.8 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:46.239714: step 5360, loss = 0.46 (430.4 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:49.211767: step 5370, loss = 0.58 (430.7 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:52.203798: step 5380, loss = 0.54 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:54:55.195030: step 5390, loss = 0.55 (428.1 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22463\n",
      "128\n",
      "2018-06-02 22:54:59.298024: step 5400, loss = 0.49 (312.0 examples/sec; 0.410 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:02.285043: step 5410, loss = 0.45 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:05.252150: step 5420, loss = 0.45 (431.3 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:08.300028: step 5430, loss = 0.49 (420.0 examples/sec; 0.305 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:11.326910: step 5440, loss = 0.44 (422.9 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:14.348826: step 5450, loss = 0.36 (423.6 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:17.369750: step 5460, loss = 0.40 (423.7 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:20.384686: step 5470, loss = 0.40 (424.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:23.364752: step 5480, loss = 0.52 (429.5 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:26.356718: step 5490, loss = 0.44 (427.8 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20281\n",
      "128\n",
      "2018-06-02 22:55:30.525604: step 5500, loss = 0.49 (307.0 examples/sec; 0.417 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:33.513580: step 5510, loss = 0.33 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:36.507576: step 5520, loss = 0.31 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:39.525505: step 5530, loss = 0.44 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:42.536453: step 5540, loss = 0.35 (425.1 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:45.520476: step 5550, loss = 0.38 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:48.499508: step 5560, loss = 0.48 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:51.479574: step 5570, loss = 0.42 (429.5 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:54.454588: step 5580, loss = 0.47 (430.5 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:55:57.448942: step 5590, loss = 0.45 (427.2 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21841\n",
      "128\n",
      "2018-06-02 22:56:01.595819: step 5600, loss = 0.69 (309.1 examples/sec; 0.414 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:04.572857: step 5610, loss = 0.35 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:07.545902: step 5620, loss = 0.41 (430.5 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:10.544680: step 5630, loss = 0.63 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:13.533687: step 5640, loss = 0.38 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:16.526715: step 5650, loss = 0.48 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:19.522672: step 5660, loss = 0.37 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:22.535615: step 5670, loss = 0.40 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:25.511689: step 5680, loss = 0.56 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:28.491690: step 5690, loss = 0.49 (429.5 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.2012\n",
      "128\n",
      "2018-06-02 22:56:32.842054: step 5700, loss = 0.52 (294.7 examples/sec; 0.434 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:35.852381: step 5710, loss = 0.57 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:38.834735: step 5720, loss = 0.42 (429.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:41.823651: step 5730, loss = 0.46 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:44.838276: step 5740, loss = 0.41 (424.6 examples/sec; 0.301 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 22:56:47.840240: step 5750, loss = 0.49 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:50.834276: step 5760, loss = 0.44 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:53.810278: step 5770, loss = 0.43 (430.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:56.787348: step 5780, loss = 0.48 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:56:59.808237: step 5790, loss = 0.45 (423.6 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22071\n",
      "128\n",
      "2018-06-02 22:57:03.884199: step 5800, loss = 0.44 (314.0 examples/sec; 0.408 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:06.858490: step 5810, loss = 0.32 (430.4 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:09.863963: step 5820, loss = 0.39 (425.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:12.858759: step 5830, loss = 0.43 (427.4 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5837 into /tmp/cifar10_train\\model.ckpt.\n",
      "128\n",
      "2018-06-02 22:57:17.929870: step 5840, loss = 0.55 (252.4 examples/sec; 0.507 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:20.940278: step 5850, loss = 0.52 (425.2 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:23.960239: step 5860, loss = 0.42 (423.8 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:26.961214: step 5870, loss = 0.44 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:29.960200: step 5880, loss = 0.54 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:32.973139: step 5890, loss = 0.57 (425.0 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.0088\n",
      "128\n",
      "2018-06-02 22:57:37.118087: step 5900, loss = 0.60 (309.1 examples/sec; 0.414 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:40.123021: step 5910, loss = 0.67 (425.3 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:43.146227: step 5920, loss = 0.36 (423.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:46.155145: step 5930, loss = 0.41 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:49.156101: step 5940, loss = 0.44 (426.5 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:52.150096: step 5950, loss = 0.56 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:55.154063: step 5960, loss = 0.49 (426.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:57:58.170994: step 5970, loss = 0.33 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:01.170013: step 5980, loss = 0.41 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:04.187907: step 5990, loss = 0.43 (424.1 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20419\n",
      "128\n",
      "2018-06-02 22:58:08.324534: step 6000, loss = 0.43 (309.4 examples/sec; 0.414 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:11.301056: step 6010, loss = 0.38 (430.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:14.300503: step 6020, loss = 0.37 (426.9 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:17.322903: step 6030, loss = 0.44 (423.5 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:20.319550: step 6040, loss = 0.38 (427.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:23.314551: step 6050, loss = 0.44 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:26.326520: step 6060, loss = 0.47 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:29.314496: step 6070, loss = 0.48 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:32.311016: step 6080, loss = 0.51 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:35.297567: step 6090, loss = 0.37 (428.5 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22408\n",
      "128\n",
      "2018-06-02 22:58:39.332908: step 6100, loss = 0.51 (317.2 examples/sec; 0.404 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:42.327650: step 6110, loss = 0.31 (427.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:45.341691: step 6120, loss = 0.28 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:48.358177: step 6130, loss = 0.50 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:51.384440: step 6140, loss = 0.48 (423.0 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:54.443727: step 6150, loss = 0.43 (418.4 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 22:58:57.647217: step 6160, loss = 0.45 (399.8 examples/sec; 0.320 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:00.719700: step 6170, loss = 0.41 (416.2 examples/sec; 0.308 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:03.733948: step 6180, loss = 0.64 (424.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:06.764846: step 6190, loss = 0.41 (422.5 examples/sec; 0.303 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.12587\n",
      "128\n",
      "2018-06-02 22:59:11.355778: step 6200, loss = 0.60 (278.7 examples/sec; 0.459 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:14.345789: step 6210, loss = 0.34 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:17.364344: step 6220, loss = 0.39 (423.9 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:20.353521: step 6230, loss = 0.36 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:23.341533: step 6240, loss = 0.30 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:26.423926: step 6250, loss = 0.37 (415.1 examples/sec; 0.308 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:29.464228: step 6260, loss = 0.47 (421.0 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:32.522930: step 6270, loss = 0.43 (418.6 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:35.559123: step 6280, loss = 0.39 (421.6 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:38.582266: step 6290, loss = 0.35 (423.3 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.17531\n",
      "128\n",
      "2018-06-02 22:59:42.833826: step 6300, loss = 0.48 (301.1 examples/sec; 0.425 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:45.851186: step 6310, loss = 0.37 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:48.874345: step 6320, loss = 0.47 (423.5 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:51.895821: step 6330, loss = 0.48 (423.6 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:54.927486: step 6340, loss = 0.45 (422.2 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 22:59:57.975974: step 6350, loss = 0.40 (419.9 examples/sec; 0.305 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:01.015614: step 6360, loss = 0.49 (421.1 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:04.090022: step 6370, loss = 0.25 (416.5 examples/sec; 0.307 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:07.122980: step 6380, loss = 0.32 (421.7 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:10.192804: step 6390, loss = 0.30 (417.0 examples/sec; 0.307 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.12799\n",
      "128\n",
      "2018-06-02 23:00:14.841237: step 6400, loss = 0.51 (276.3 examples/sec; 0.463 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:17.907628: step 6410, loss = 0.42 (415.4 examples/sec; 0.308 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:20.938568: step 6420, loss = 0.46 (422.5 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:23.970977: step 6430, loss = 0.43 (422.0 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:27.010940: step 6440, loss = 0.40 (421.1 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:30.026641: step 6450, loss = 0.48 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:33.047912: step 6460, loss = 0.34 (423.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:36.157056: step 6470, loss = 0.49 (411.7 examples/sec; 0.311 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:39.169979: step 6480, loss = 0.40 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:42.191711: step 6490, loss = 0.47 (423.6 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.1681\n",
      "128\n",
      "2018-06-02 23:00:46.380032: step 6500, loss = 0.39 (306.0 examples/sec; 0.418 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:49.390267: step 6510, loss = 0.45 (424.5 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:52.369345: step 6520, loss = 0.40 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:55.411291: step 6530, loss = 0.55 (420.8 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:00:58.436773: step 6540, loss = 0.50 (423.1 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:01.457672: step 6550, loss = 0.37 (423.9 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:04.469684: step 6560, loss = 0.39 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:07.496304: step 6570, loss = 0.49 (422.9 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:10.510535: step 6580, loss = 0.35 (424.7 examples/sec; 0.301 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 23:01:13.497150: step 6590, loss = 0.33 (428.6 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.18898\n",
      "128\n",
      "2018-06-02 23:01:17.716966: step 6600, loss = 0.34 (303.3 examples/sec; 0.422 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:20.699959: step 6610, loss = 0.61 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:23.718886: step 6620, loss = 0.34 (424.0 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:26.699930: step 6630, loss = 0.39 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:29.682938: step 6640, loss = 0.49 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:32.676930: step 6650, loss = 0.33 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:35.657960: step 6660, loss = 0.42 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:38.644971: step 6670, loss = 0.34 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:41.627995: step 6680, loss = 0.22 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:44.604039: step 6690, loss = 0.52 (430.1 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22435\n",
      "128\n",
      "2018-06-02 23:01:48.737022: step 6700, loss = 0.40 (310.2 examples/sec; 0.413 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:51.716020: step 6710, loss = 0.32 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:54.687077: step 6720, loss = 0.33 (430.8 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:01:57.663127: step 6730, loss = 0.42 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:00.639169: step 6740, loss = 0.40 (430.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:03.670056: step 6750, loss = 0.46 (422.2 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:06.685370: step 6760, loss = 0.36 (424.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:09.684268: step 6770, loss = 0.28 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:12.690431: step 6780, loss = 0.48 (425.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:15.718396: step 6790, loss = 0.40 (422.6 examples/sec; 0.303 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21028\n",
      "128\n",
      "2018-06-02 23:02:19.869096: step 6800, loss = 0.32 (308.4 examples/sec; 0.415 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:22.868611: step 6810, loss = 0.42 (426.9 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:25.893264: step 6820, loss = 0.32 (423.1 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:28.896079: step 6830, loss = 0.48 (426.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:31.909327: step 6840, loss = 0.32 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:34.915288: step 6850, loss = 0.43 (425.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:37.918228: step 6860, loss = 0.56 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:40.927217: step 6870, loss = 0.49 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:43.912751: step 6880, loss = 0.35 (428.9 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:46.891743: step 6890, loss = 0.31 (429.5 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22349\n",
      "128\n",
      "2018-06-02 23:02:50.905280: step 6900, loss = 0.34 (318.9 examples/sec; 0.401 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:53.897522: step 6910, loss = 0.38 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:56.876212: step 6920, loss = 0.45 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:02:59.878632: step 6930, loss = 0.45 (426.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:02.882314: step 6940, loss = 0.47 (426.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:05.877598: step 6950, loss = 0.45 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:08.862026: step 6960, loss = 0.31 (428.9 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:11.871086: step 6970, loss = 0.34 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:14.879809: step 6980, loss = 0.39 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:17.871674: step 6990, loss = 0.35 (427.8 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.2174\n",
      "128\n",
      "2018-06-02 23:03:21.985310: step 7000, loss = 0.36 (311.2 examples/sec; 0.411 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:24.984587: step 7010, loss = 0.37 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:27.987627: step 7020, loss = 0.39 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:31.001027: step 7030, loss = 0.37 (424.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:33.993349: step 7040, loss = 0.36 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:36.958638: step 7050, loss = 0.37 (431.8 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:39.935678: step 7060, loss = 0.52 (429.8 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:42.911435: step 7070, loss = 0.31 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:45.904470: step 7080, loss = 0.32 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:48.878317: step 7090, loss = 0.46 (430.4 examples/sec; 0.297 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.24138\n",
      "128\n",
      "2018-06-02 23:03:52.842926: step 7100, loss = 0.44 (323.5 examples/sec; 0.396 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:55.819956: step 7110, loss = 0.46 (428.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:03:58.815410: step 7120, loss = 0.46 (427.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:01.775623: step 7130, loss = 0.49 (432.4 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:04.774421: step 7140, loss = 0.37 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:07.745910: step 7150, loss = 0.48 (430.8 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:10.716699: step 7160, loss = 0.41 (431.0 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:13.686207: step 7170, loss = 0.40 (430.9 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:16.680746: step 7180, loss = 0.28 (427.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:19.675721: step 7190, loss = 0.48 (427.5 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21866\n",
      "128\n",
      "2018-06-02 23:04:23.913242: step 7200, loss = 0.46 (302.6 examples/sec; 0.423 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:26.896064: step 7210, loss = 0.48 (428.0 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:29.872419: step 7220, loss = 0.60 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:32.843432: step 7230, loss = 0.30 (430.8 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:35.825781: step 7240, loss = 0.35 (429.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:38.805552: step 7250, loss = 0.41 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:41.788800: step 7260, loss = 0.36 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:44.780137: step 7270, loss = 0.40 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:47.781817: step 7280, loss = 0.40 (426.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:50.786735: step 7290, loss = 0.47 (426.0 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21366\n",
      "128\n",
      "2018-06-02 23:04:55.048342: step 7300, loss = 0.30 (301.2 examples/sec; 0.425 sec/batch)\n",
      "128\n",
      "2018-06-02 23:04:58.033358: step 7310, loss = 0.46 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:01.069249: step 7320, loss = 0.35 (421.6 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:04.095168: step 7330, loss = 0.27 (423.0 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:07.193150: step 7340, loss = 0.36 (413.2 examples/sec; 0.310 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:10.255471: step 7350, loss = 0.44 (418.0 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:13.294136: step 7360, loss = 0.42 (421.1 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:16.302740: step 7370, loss = 0.40 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:19.281266: step 7380, loss = 0.34 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:22.268081: step 7390, loss = 0.43 (428.6 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.17291\n",
      "128\n",
      "2018-06-02 23:05:26.537647: step 7400, loss = 0.37 (300.5 examples/sec; 0.426 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:29.510219: step 7410, loss = 0.44 (429.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:32.514173: step 7420, loss = 0.26 (426.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:35.489380: step 7430, loss = 0.44 (430.2 examples/sec; 0.298 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 23:05:38.456981: step 7440, loss = 0.37 (431.5 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:41.448332: step 7450, loss = 0.34 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:44.434120: step 7460, loss = 0.29 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:47.410451: step 7470, loss = 0.23 (430.1 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:50.387492: step 7480, loss = 0.36 (430.0 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:05:53.372174: step 7490, loss = 0.48 (428.9 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.23099\n",
      "128\n",
      "2018-06-02 23:05:57.492433: step 7500, loss = 0.41 (311.2 examples/sec; 0.411 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:00.508376: step 7510, loss = 0.27 (423.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:03.492775: step 7520, loss = 0.41 (428.9 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:06.463549: step 7530, loss = 0.27 (430.9 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:09.477442: step 7540, loss = 0.32 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:12.447018: step 7550, loss = 0.45 (433.3 examples/sec; 0.295 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:15.430336: step 7560, loss = 0.27 (426.8 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:18.420749: step 7570, loss = 0.54 (428.0 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:21.431452: step 7580, loss = 0.46 (425.1 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:24.451771: step 7590, loss = 0.31 (423.8 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.2014\n",
      "128\n",
      "2018-06-02 23:06:28.722757: step 7600, loss = 0.34 (299.7 examples/sec; 0.427 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:31.712852: step 7610, loss = 0.46 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:34.700840: step 7620, loss = 0.34 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:37.697794: step 7630, loss = 0.34 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:40.700801: step 7640, loss = 0.26 (426.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:43.678842: step 7650, loss = 0.27 (429.8 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:46.640983: step 7660, loss = 0.39 (432.1 examples/sec; 0.296 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:49.628053: step 7670, loss = 0.34 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:52.594384: step 7680, loss = 0.38 (431.5 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:06:55.580758: step 7690, loss = 0.31 (428.6 examples/sec; 0.299 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21969\n",
      "128\n",
      "2018-06-02 23:06:59.781167: step 7700, loss = 0.49 (304.7 examples/sec; 0.420 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:02.771001: step 7710, loss = 0.48 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:05.746044: step 7720, loss = 0.25 (430.2 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:08.723992: step 7730, loss = 0.38 (429.8 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:11.705531: step 7740, loss = 0.38 (429.3 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7751 into /tmp/cifar10_train\\model.ckpt.\n",
      "128\n",
      "2018-06-02 23:07:16.486537: step 7750, loss = 0.34 (267.8 examples/sec; 0.478 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:19.465571: step 7760, loss = 0.22 (429.5 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:22.475522: step 7770, loss = 0.33 (425.3 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:25.513512: step 7780, loss = 0.29 (421.5 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:28.530794: step 7790, loss = 0.46 (424.2 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.02881\n",
      "128\n",
      "2018-06-02 23:07:32.809866: step 7800, loss = 0.35 (299.1 examples/sec; 0.428 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:35.831851: step 7810, loss = 0.31 (423.6 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:38.888533: step 7820, loss = 0.38 (418.8 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:41.959763: step 7830, loss = 0.42 (416.9 examples/sec; 0.307 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:44.999675: step 7840, loss = 0.32 (420.9 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:48.012737: step 7850, loss = 0.27 (425.0 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:51.002606: step 7860, loss = 0.29 (428.0 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:53.995757: step 7870, loss = 0.43 (427.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:07:56.992743: step 7880, loss = 0.35 (427.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:00.009480: step 7890, loss = 0.26 (424.3 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19027\n",
      "128\n",
      "2018-06-02 23:08:04.148179: step 7900, loss = 0.29 (309.3 examples/sec; 0.414 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:07.144306: step 7910, loss = 0.36 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:10.207549: step 7920, loss = 0.41 (418.0 examples/sec; 0.306 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:13.312962: step 7930, loss = 0.33 (412.2 examples/sec; 0.311 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:16.322324: step 7940, loss = 0.43 (425.2 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:19.319083: step 7950, loss = 0.29 (427.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:22.323416: step 7960, loss = 0.31 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:25.334907: step 7970, loss = 0.38 (424.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:28.364747: step 7980, loss = 0.31 (422.5 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:31.394618: step 7990, loss = 0.34 (422.5 examples/sec; 0.303 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.18152\n",
      "128\n",
      "2018-06-02 23:08:35.591610: step 8000, loss = 0.34 (305.6 examples/sec; 0.419 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:38.613209: step 8010, loss = 0.49 (422.5 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:41.618503: step 8020, loss = 0.35 (425.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:44.639441: step 8030, loss = 0.26 (423.7 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:47.674162: step 8040, loss = 0.23 (421.8 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:50.703860: step 8050, loss = 0.28 (422.8 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:53.737499: step 8060, loss = 0.25 (421.7 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:56.753875: step 8070, loss = 0.39 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:08:59.752383: step 8080, loss = 0.31 (426.9 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:02.748552: step 8090, loss = 0.37 (427.2 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.2026\n",
      "128\n",
      "2018-06-02 23:09:06.812001: step 8100, loss = 0.37 (316.2 examples/sec; 0.405 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:09.809345: step 8110, loss = 0.37 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:12.813737: step 8120, loss = 0.38 (426.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:15.807719: step 8130, loss = 0.34 (427.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:18.811310: step 8140, loss = 0.23 (426.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:21.803851: step 8150, loss = 0.45 (427.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:24.775816: step 8160, loss = 0.37 (430.7 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:27.792582: step 8170, loss = 0.33 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:30.805192: step 8180, loss = 0.29 (424.9 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:33.803695: step 8190, loss = 0.27 (426.9 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21462\n",
      "128\n",
      "2018-06-02 23:09:37.906149: step 8200, loss = 0.41 (312.0 examples/sec; 0.410 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:40.898721: step 8210, loss = 0.27 (427.9 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:43.905750: step 8220, loss = 0.49 (425.5 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:46.897751: step 8230, loss = 0.31 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:49.891744: step 8240, loss = 0.49 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:52.892257: step 8250, loss = 0.38 (426.7 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:55.886051: step 8260, loss = 0.35 (427.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:09:58.872200: step 8270, loss = 0.34 (428.6 examples/sec; 0.299 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 23:10:01.874509: step 8280, loss = 0.36 (426.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:04.854128: step 8290, loss = 0.33 (429.6 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22987\n",
      "128\n",
      "2018-06-02 23:10:08.877558: step 8300, loss = 0.41 (318.8 examples/sec; 0.402 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:11.866083: step 8310, loss = 0.45 (427.2 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:14.845377: step 8320, loss = 0.31 (429.6 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:17.824421: step 8330, loss = 0.31 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:20.813082: step 8340, loss = 0.48 (428.3 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:23.801522: step 8350, loss = 0.34 (428.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:26.829160: step 8360, loss = 0.45 (422.8 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:29.848335: step 8370, loss = 0.43 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:32.887287: step 8380, loss = 0.39 (421.1 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:35.923989: step 8390, loss = 0.31 (421.4 examples/sec; 0.304 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19124\n",
      "128\n",
      "2018-06-02 23:10:40.231309: step 8400, loss = 0.50 (297.8 examples/sec; 0.430 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:43.267761: step 8410, loss = 0.26 (420.4 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:46.293656: step 8420, loss = 0.29 (422.9 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:49.326819: step 8430, loss = 0.32 (422.0 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:52.339680: step 8440, loss = 0.36 (424.8 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:55.353526: step 8450, loss = 0.36 (424.7 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:10:58.371396: step 8460, loss = 0.37 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:01.389328: step 8470, loss = 0.34 (424.0 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:04.407257: step 8480, loss = 0.27 (424.1 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:07.406238: step 8490, loss = 0.28 (426.8 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19383\n",
      "128\n",
      "2018-06-02 23:11:11.528216: step 8500, loss = 0.25 (310.5 examples/sec; 0.412 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:14.551259: step 8510, loss = 0.30 (423.6 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:17.598861: step 8520, loss = 0.27 (419.9 examples/sec; 0.305 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:20.592187: step 8530, loss = 0.34 (427.6 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:23.609580: step 8540, loss = 0.31 (424.2 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:26.679372: step 8550, loss = 0.25 (417.0 examples/sec; 0.307 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:29.658232: step 8560, loss = 0.43 (429.7 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:32.682388: step 8570, loss = 0.46 (423.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:35.652686: step 8580, loss = 0.36 (430.9 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:38.624026: step 8590, loss = 0.45 (430.8 examples/sec; 0.297 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.21299\n",
      "128\n",
      "2018-06-02 23:11:42.629223: step 8600, loss = 0.33 (319.6 examples/sec; 0.401 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:45.596332: step 8610, loss = 0.36 (431.4 examples/sec; 0.297 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:48.590874: step 8620, loss = 0.33 (427.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:51.578662: step 8630, loss = 0.36 (428.4 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:54.568138: step 8640, loss = 0.28 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:11:57.611001: step 8650, loss = 0.25 (420.7 examples/sec; 0.304 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:00.600018: step 8660, loss = 0.26 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:03.594999: step 8670, loss = 0.27 (427.5 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:06.615975: step 8680, loss = 0.28 (423.6 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:09.612710: step 8690, loss = 0.28 (427.1 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.22874\n",
      "128\n",
      "2018-06-02 23:12:13.624979: step 8700, loss = 0.40 (319.9 examples/sec; 0.400 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:16.615867: step 8710, loss = 0.33 (426.4 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:19.601563: step 8720, loss = 0.26 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:22.623363: step 8730, loss = 0.32 (423.6 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:25.631195: step 8740, loss = 0.34 (425.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:28.620987: step 8750, loss = 0.28 (428.1 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:31.619809: step 8760, loss = 0.26 (427.0 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:34.635563: step 8770, loss = 0.40 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:37.626671: step 8780, loss = 0.35 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:40.622060: step 8790, loss = 0.42 (427.0 examples/sec; 0.300 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.19213\n",
      "128\n",
      "2018-06-02 23:12:44.946808: step 8800, loss = 0.33 (296.5 examples/sec; 0.432 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:47.971030: step 8810, loss = 0.35 (422.3 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:50.970429: step 8820, loss = 0.45 (426.6 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:53.992184: step 8830, loss = 0.46 (423.9 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:12:57.009366: step 8840, loss = 0.49 (424.0 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:00.028381: step 8850, loss = 0.38 (424.3 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:03.041013: step 8860, loss = 0.31 (424.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:06.057198: step 8870, loss = 0.31 (424.4 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:09.050291: step 8880, loss = 0.29 (427.8 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:12.067308: step 8890, loss = 0.45 (424.1 examples/sec; 0.302 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.20178\n",
      "128\n",
      "2018-06-02 23:13:16.183419: step 8900, loss = 0.24 (311.5 examples/sec; 0.411 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:19.185184: step 8910, loss = 0.28 (425.4 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:22.230509: step 8920, loss = 0.31 (420.3 examples/sec; 0.305 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:25.319734: step 8930, loss = 0.32 (414.9 examples/sec; 0.309 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:28.454833: step 8940, loss = 0.36 (407.8 examples/sec; 0.314 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:31.458461: step 8950, loss = 0.35 (426.3 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:34.479926: step 8960, loss = 0.32 (423.6 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:37.499489: step 8970, loss = 0.33 (423.8 examples/sec; 0.302 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:40.531741: step 8980, loss = 0.43 (422.1 examples/sec; 0.303 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:43.539492: step 8990, loss = 0.23 (425.6 examples/sec; 0.301 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.14712\n",
      "128\n",
      "2018-06-02 23:13:47.949560: step 9000, loss = 0.28 (290.7 examples/sec; 0.440 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:50.928042: step 9010, loss = 0.39 (428.7 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:53.928663: step 9020, loss = 0.31 (426.6 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:56.925505: step 9030, loss = 0.32 (427.1 examples/sec; 0.300 sec/batch)\n",
      "128\n",
      "2018-06-02 23:13:59.915105: step 9040, loss = 0.24 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:14:02.922738: step 9050, loss = 0.33 (425.6 examples/sec; 0.301 sec/batch)\n",
      "128\n",
      "2018-06-02 23:14:05.903527: step 9060, loss = 0.29 (429.4 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:14:08.893126: step 9070, loss = 0.31 (428.2 examples/sec; 0.299 sec/batch)\n",
      "128\n",
      "2018-06-02 23:14:11.870796: step 9080, loss = 0.23 (429.9 examples/sec; 0.298 sec/batch)\n",
      "128\n",
      "2018-06-02 23:14:14.851593: step 9090, loss = 0.37 (429.4 examples/sec; 0.298 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.2122\n",
      "128\n",
      "2018-06-02 23:14:19.089581: step 9100, loss = 0.30 (302.5 examples/sec; 0.423 sec/batch)\n",
      "128\n",
      "2018-06-02 23:14:28.768337: step 9110, loss = 0.30 (132.2 examples/sec; 0.969 sec/batch)\n",
      "128\n",
      "2018-06-02 23:15:08.085467: step 9120, loss = 0.40 (32.6 examples/sec; 3.932 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2018-06-02 23:15:43.200468: step 9130, loss = 0.37 (36.5 examples/sec; 3.512 sec/batch)\n",
      "128\n",
      "2018-06-02 23:15:51.603992: step 9140, loss = 0.29 (152.3 examples/sec; 0.840 sec/batch)\n",
      "128\n",
      "2018-06-02 23:15:55.398845: step 9150, loss = 0.29 (337.3 examples/sec; 0.379 sec/batch)\n",
      "128\n",
      "2018-06-02 23:15:59.253539: step 9160, loss = 0.37 (332.1 examples/sec; 0.385 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:03.543069: step 9170, loss = 0.37 (298.5 examples/sec; 0.429 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:09.206892: step 9180, loss = 0.28 (226.0 examples/sec; 0.566 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:13.211184: step 9190, loss = 0.34 (319.6 examples/sec; 0.401 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.832063\n",
      "128\n",
      "2018-06-02 23:16:19.285966: step 9200, loss = 0.31 (211.1 examples/sec; 0.606 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:23.172544: step 9210, loss = 0.31 (328.6 examples/sec; 0.390 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:27.084084: step 9220, loss = 0.29 (327.2 examples/sec; 0.391 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:30.995626: step 9230, loss = 0.33 (327.3 examples/sec; 0.391 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:34.932099: step 9240, loss = 0.33 (325.2 examples/sec; 0.394 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:38.829678: step 9250, loss = 0.33 (328.2 examples/sec; 0.390 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:42.758173: step 9260, loss = 0.29 (325.9 examples/sec; 0.393 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:46.776429: step 9270, loss = 0.39 (318.5 examples/sec; 0.402 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:50.692969: step 9280, loss = 0.23 (326.8 examples/sec; 0.392 sec/batch)\n",
      "128\n",
      "2018-06-02 23:16:54.590532: step 9290, loss = 0.29 (328.5 examples/sec; 0.390 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.46376\n",
      "128\n",
      "2018-06-02 23:16:59.878394: step 9300, loss = 0.34 (242.5 examples/sec; 0.528 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:03.757022: step 9310, loss = 0.29 (329.1 examples/sec; 0.389 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:07.689506: step 9320, loss = 0.26 (325.7 examples/sec; 0.393 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:09.972403: step 9330, loss = 0.31 (560.4 examples/sec; 0.228 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:12.275245: step 9340, loss = 0.24 (555.8 examples/sec; 0.230 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 9351 into /tmp/cifar10_train\\model.ckpt.\n",
      "128\n",
      "2018-06-02 23:17:17.050478: step 9350, loss = 0.27 (268.0 examples/sec; 0.478 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:19.205712: step 9360, loss = 0.24 (593.6 examples/sec; 0.216 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:21.398848: step 9370, loss = 0.22 (583.6 examples/sec; 0.219 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:23.602954: step 9380, loss = 0.20 (580.7 examples/sec; 0.220 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:25.803073: step 9390, loss = 0.27 (582.1 examples/sec; 0.220 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 3.32441\n",
      "128\n",
      "2018-06-02 23:17:29.976911: step 9400, loss = 0.35 (307.8 examples/sec; 0.416 sec/batch)\n",
      "128\n",
      "2018-06-02 23:17:46.192843: step 9410, loss = 0.26 (78.9 examples/sec; 1.623 sec/batch)\n",
      "128\n",
      "2018-06-02 23:18:01.566733: step 9420, loss = 0.34 (83.3 examples/sec; 1.537 sec/batch)\n",
      "128\n",
      "2018-06-02 23:18:22.640383: step 9430, loss = 0.34 (60.7 examples/sec; 2.107 sec/batch)\n",
      "128\n",
      "2018-06-02 23:18:42.784517: step 9440, loss = 0.22 (63.5 examples/sec; 2.014 sec/batch)\n",
      "128\n",
      "2018-06-02 23:19:02.815954: step 9450, loss = 0.36 (63.9 examples/sec; 2.003 sec/batch)\n",
      "128\n",
      "2018-06-02 23:19:22.534228: step 9460, loss = 0.26 (64.9 examples/sec; 1.972 sec/batch)\n",
      "128\n",
      "2018-06-02 23:19:42.822976: step 9470, loss = 0.37 (63.1 examples/sec; 2.029 sec/batch)\n",
      "128\n",
      "2018-06-02 23:20:03.057868: step 9480, loss = 0.25 (63.3 examples/sec; 2.023 sec/batch)\n",
      "128\n",
      "2018-06-02 23:20:25.498862: step 9490, loss = 0.25 (57.0 examples/sec; 2.244 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.503977\n",
      "128\n",
      "2018-06-02 23:20:48.430542: step 9500, loss = 0.40 (55.8 examples/sec; 2.292 sec/batch)\n",
      "128\n",
      "2018-06-02 23:21:06.783467: step 9510, loss = 0.36 (69.7 examples/sec; 1.836 sec/batch)\n",
      "128\n",
      "2018-06-02 23:21:25.380738: step 9520, loss = 0.25 (68.8 examples/sec; 1.860 sec/batch)\n",
      "128\n",
      "2018-06-02 23:21:44.408857: step 9530, loss = 0.33 (67.3 examples/sec; 1.903 sec/batch)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d7a4f547d1c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m     46\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-d7a4f547d1c1>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m   \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-d7a4f547d1c1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    109\u001b[0m             log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n\u001b[0;32m    110\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    516\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    860\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    970\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cindy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"A binary to train CIFAR-10 using a single GPU.\n",
    "Accuracy:\n",
    "cifar10_train.py achieves ~86% accuracy after 100K steps (256 epochs of\n",
    "data) as judged by cifar10_eval.py.\n",
    "Speed: With batch_size 128.\n",
    "System        | Step Time (sec/batch)  |     Accuracy\n",
    "------------------------------------------------------------------\n",
    "1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)\n",
    "1 Tesla K40m  | 0.25-0.35              | ~86% at 100K steps (4 hours)\n",
    "Usage:\n",
    "Please see the tutorial and website for how to download the CIFAR-10\n",
    "data set, compile the program and train the model.\n",
    "http://tensorflow.org/tutorials/deep_cnn/\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cifar10\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 1000000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('log_frequency', 10,\n",
    "                            \"\"\"How often to log results to the console.\"\"\")\n",
    "\n",
    "\n",
    "def train():\n",
    "  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    # Force input pipeline to CPU:0 to avoid operations sometimes ending up on\n",
    "    # GPU and resulting in a slow down.\n",
    "    with tf.device('/cpu:0'):\n",
    "      images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.b\n",
    "    logits = cifar10.inference(images)\n",
    "\n",
    "    # Calculate loss.\n",
    "    loss = cifar10.loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "    class _LoggerHook(tf.train.SessionRunHook):\n",
    "      \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "      def begin(self):\n",
    "        self._step = -1\n",
    "        self._start_time = time.time()\n",
    "\n",
    "      def before_run(self, run_context):\n",
    "        self._step += 1\n",
    "        return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
    "\n",
    "      def after_run(self, run_context, run_values):\n",
    "        if self._step % FLAGS.log_frequency == 0:\n",
    "          current_time = time.time()\n",
    "          duration = current_time - self._start_time\n",
    "          self._start_time = current_time\n",
    "\n",
    "          loss_value = run_values.results\n",
    "          print(FLAGS.batch_size)\n",
    "          examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
    "          sec_per_batch = float(duration / FLAGS.log_frequency)\n",
    "\n",
    "          format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                        'sec/batch)')\n",
    "          print (format_str % (datetime.now(), self._step, loss_value,\n",
    "                               examples_per_sec, sec_per_batch))\n",
    "\n",
    "    with tf.train.MonitoredTrainingSession(\n",
    "        checkpoint_dir=FLAGS.train_dir,\n",
    "        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
    "               tf.train.NanTensorHook(loss),\n",
    "               _LoggerHook()],\n",
    "        config=tf.ConfigProto(\n",
    "            log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n",
    "      while not mon_sess.should_stop():\n",
    "        mon_sess.run(train_op)\n",
    "\n",
    "\n",
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "  cifar10.maybe_download_and_extract()\n",
    "  if tf.gfile.Exists(FLAGS.train_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "  tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "  train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
